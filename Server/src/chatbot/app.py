#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import json
import os
import argparse
import re
from flask import Flask, request, jsonify
import openai
from openai import OpenAI
from dotenv import load_dotenv
from db_connector import get_product_data

load_dotenv()

app = Flask(__name__)

# C·∫•u h√¨nh API key ƒë√∫ng c√°ch
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# L∆∞u tr·ªØ c√¢u tr·∫£ l·ªùi cu·ªëi c√πng cho m·ªói phi√™n
last_responses = {}

@app.route('/api/chatbot/ask', methods=['POST'])
def ask():
    data = request.json
    question = data.get("question", "")
    session_id = data.get("session_id", "default")
    
    if not question:
        return jsonify({"answer": "B·∫°n ch∆∞a nh·∫≠p c√¢u h·ªèi."}), 400

    # Ki·ªÉm tra xem c√≥ ph·∫£i y√™u c·∫ßu t√¨m nguy√™n li·ªáu kh√¥ng
    if "t√¨m" in question.lower() and ("nguy√™n li·ªáu" in question.lower() or "nh∆∞ tr√™n" in question.lower()):
        # L·∫•y c√¢u tr·∫£ l·ªùi cu·ªëi c√πng c·ªßa phi√™n n√†y
        last_response = last_responses.get(session_id, "")
        
        if not last_response:
            return jsonify({"answer": "T√¥i ch∆∞a c√≥ th√¥ng tin v·ªÅ nguy√™n li·ªáu n√†o. Vui l√≤ng h·ªèi v·ªÅ m·ªôt m√≥n ƒÉn tr∆∞·ªõc."})
        
        # Tr√≠ch xu·∫•t danh s√°ch nguy√™n li·ªáu t·ª´ c√¢u tr·∫£ l·ªùi cu·ªëi
        ingredients = extract_ingredients(last_response)
        
        if not ingredients:
            return jsonify({"answer": "T√¥i kh√¥ng t√¨m th·∫•y nguy√™n li·ªáu n√†o trong th√¥ng tin tr∆∞·ªõc ƒë√≥."})
        
        # Ki·ªÉm tra xem nguy√™n li·ªáu n√†o c√≥ trong c·ª≠a h√†ng
        ingredient_results = check_ingredient_availability(ingredients)
        
        # T·∫°o c√¢u tr·∫£ l·ªùi
        answer = "üõí **K·∫øt qu·∫£ t√¨m ki·∫øm nguy√™n li·ªáu trong c·ª≠a h√†ng:**\n\n"
        
        # Ph√¢n lo·∫°i nguy√™n li·ªáu c√≥ s·∫µn v√† kh√¥ng c√≥ s·∫µn
        available = []
        unavailable = []
        alternatives_info = {}
        
        for ingredient, info in ingredient_results.items():
            if info["available"]:
                product_info = f"- **{ingredient}**: ‚úÖ C√≥ s·∫µn\n"
                product_info += f"  ‚Üí {info['product_name'].title()}: {format_price(info['price'])} / {info['unit']}\n"
                
                # Th√™m th√¥ng tin t·ªìn kho n·∫øu c√≥
                if isinstance(info.get("stock"), int):
                    if info["stock"] > 0:
                        product_info += f"  ‚Üí S·ªë l∆∞·ª£ng t·ªìn: {info['stock']} {info['unit']}\n"
                    else:
                        product_info += f"  ‚Üí H·∫øt h√†ng (ƒëang nh·∫≠p th√™m)\n"
                        
                available.append(product_info)
            else:
                unavailable.append(f"- **{ingredient}**: ‚ùå Kh√¥ng c√≥ s·∫µn\n")
                
                # T√¨m s·∫£n ph·∫©m thay th·∫ø
                alternatives = suggest_alternative_products(ingredient)
                if alternatives:
                    alternatives_info[ingredient] = alternatives
        
        # Hi·ªÉn th·ªã nguy√™n li·ªáu c√≥ s·∫µn tr∆∞·ªõc
        if available:
            answer += "**Nguy√™n li·ªáu c√≥ s·∫µn:**\n"
            answer += "".join(available)
            answer += "\n"
        
        # Hi·ªÉn th·ªã nguy√™n li·ªáu kh√¥ng c√≥ s·∫µn
        if unavailable:
            answer += "**Nguy√™n li·ªáu kh√¥ng c√≥ s·∫µn:**\n"
            answer += "".join(unavailable)
            
            # Hi·ªÉn th·ªã s·∫£n ph·∫©m thay th·∫ø
            if alternatives_info:
                answer += "\n**S·∫£n ph·∫©m thay th·∫ø g·ª£i √Ω:**\n"
                for ingredient, alternatives in alternatives_info.items():
                    answer += f"Thay th·∫ø cho {ingredient}:\n"
                    for alt in alternatives:
                        answer += f"  ‚Üí {alt['name']}: {format_price(alt['price'])} / {alt['unit']}\n"
                    answer += "\n"
        
        # Th√™m g·ª£i √Ω
        if unavailable:
            answer += "\nüí° *B·∫°n c√≥ th·ªÉ ƒë·∫∑t h√†ng tr∆∞·ªõc c√°c nguy√™n li·ªáu kh√¥ng c√≥ s·∫µn ho·∫∑c s·ª≠ d·ª•ng s·∫£n ph·∫©m thay th·∫ø.*"
        else:
            answer += "\nüí° *T·∫•t c·∫£ nguy√™n li·ªáu ƒë·ªÅu c√≥ s·∫µn trong c·ª≠a h√†ng. Ch√∫c b·∫°n n·∫•u ƒÉn ngon mi·ªáng!*"
        
        return jsonify({"answer": answer})
    
    try:
        # G·ªçi OpenAI API ƒë√∫ng c√°ch v·ªõi th∆∞ vi·ªán m·ªõi
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n th·ª±c ph·∫©m, tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, th√¢n thi·ªán."},
                {"role": "user", "content": question}
            ],
            max_tokens=300,
            temperature=0.7
        )
        answer = response.choices[0].message.content.strip()
        print(f"C√¢u h·ªèi: {question}")
        print(f"C√¢u tr·∫£ l·ªùi: {answer}")
        
        # L∆∞u c√¢u tr·∫£ l·ªùi cho phi√™n n√†y
        last_responses[session_id] = answer
        
        return jsonify({"answer": answer})
    except Exception as e:
        print(f"L·ªói OpenAI: {str(e)}")
        return jsonify({"answer": f"L·ªói khi g·ªçi OpenAI: {str(e)}"}), 500

def extract_ingredients(text):
    """Tr√≠ch xu·∫•t danh s√°ch nguy√™n li·ªáu t·ª´ vƒÉn b·∫£n"""
    ingredients = []
    
    # T√¨m danh s√°ch ƒë√°nh s·ªë
    numbered_list = re.findall(r'\d+\.\s+(.*?)(?=\d+\.|$)', text, re.DOTALL)
    if numbered_list:
        for item in numbered_list:
            # L·∫•y t√™n nguy√™n li·ªáu (ph·∫ßn ƒë·∫ßu ti√™n tr∆∞·ªõc d·∫•u ph·∫©y ho·∫∑c d·∫•u ngo·∫∑c)
            ingredient = re.split(r'[,\(:]', item.strip())[0].strip()
            if ingredient and len(ingredient) > 1:  # Tr√°nh c√°c k·∫øt qu·∫£ qu√° ng·∫Øn
                ingredients.append(ingredient)
    
    # T√¨m danh s√°ch d·∫•u g·∫°ch ƒë·∫ßu d√≤ng
    bullet_list = re.findall(r'[-‚Ä¢*]\s+(.*?)(?=[-‚Ä¢*]|$)', text, re.DOTALL)
    if bullet_list:
        for item in bullet_list:
            ingredient = re.split(r'[,\(:]', item.strip())[0].strip()
            if ingredient and len(ingredient) > 1:
                ingredients.append(ingredient)
    
    # T√¨m danh s√°ch trong c√°c ph·∫ßn ƒë∆∞·ª£c ƒë√°nh d·∫•u
    sections = ["nguy√™n li·ªáu ch√≠nh", "nguy√™n li·ªáu", "gia v·ªã", "nguy√™n li·ªáu ph·ª•", "th√†nh ph·∫ßn"]
    for section in sections:
        if section in text.lower():
            # T√¨m ph·∫ßn vƒÉn b·∫£n sau section v√† tr∆∞·ªõc section ti·∫øp theo ho·∫∑c k·∫øt th√∫c
            section_pattern = f"{section}(.*?)(?:{'|'.join(sections)}|$)"
            section_matches = re.findall(section_pattern, text.lower(), re.DOTALL | re.IGNORECASE)
            
            if section_matches:
                for section_text in section_matches:
                    # T√¨m c√°c d√≤ng trong ph·∫ßn n√†y
                    lines = section_text.split('\n')
                    for line in lines:
                        line = line.strip()
                        if line and not line.startswith((':', '.', '#', '##')) and len(line) > 1:
                            # Lo·∫°i b·ªè c√°c t·ª´ kh√≥a kh√¥ng ph·∫£i nguy√™n li·ªáu
                            non_ingredient_words = ["l∆∞·ª£ng", "gram", "kg", "c·∫ßn", "y√™u c·∫ßu", "chu·∫©n b·ªã"]
                            if not any(word in line.lower() for word in non_ingredient_words):
                                # L·∫•y ph·∫ßn ƒë·∫ßu ti√™n c·ªßa d√≤ng (tr∆∞·ªõc d·∫•u ph·∫©y, d·∫•u hai ch·∫•m ho·∫∑c d·∫•u ngo·∫∑c)
                                ingredient = re.split(r'[,\(:]', line)[0].strip()
                                if ingredient and len(ingredient) > 1:
                                    ingredients.append(ingredient)
    
    # N·∫øu kh√¥ng t√¨m th·∫•y danh s√°ch theo c√°ch tr√™n, th·ª≠ ph√¢n t√≠ch t·ª´ng d√≤ng
    if not ingredients:
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            # T√¨m c√°c d√≤ng c√≥ th·ªÉ ch·ª©a nguy√™n li·ªáu
            if line and len(line) < 100 and not line.startswith(('#', '##', '>')):
                # Ki·ªÉm tra xem d√≤ng c√≥ ch·ª©a c√°c t·ª´ kh√≥a li√™n quan ƒë·∫øn s·ªë l∆∞·ª£ng kh√¥ng
                quantity_keywords = ["gram", "kg", "g", "ml", "l√≠t", "mu·ªóng", "ch√©n", "c·ªß", "qu·∫£", "c√°i"]
                if any(keyword in line.lower() for keyword in quantity_keywords):
                    # L·∫•y ph·∫ßn ƒë·∫ßu ti√™n c·ªßa d√≤ng (tr∆∞·ªõc s·ªë l∆∞·ª£ng)
                    parts = re.split(r'[:‚Äì\-]', line)
                    if parts:
                        ingredient = parts[0].strip()
                        if ingredient and len(ingredient) > 1:
                            ingredients.append(ingredient)
    
    # Chu·∫©n h√≥a v√† nh√≥m c√°c nguy√™n li·ªáu t∆∞∆°ng t·ª±
    normalized_ingredients = []
    seen = set()
    
    # √Ånh x·∫° c√°c nguy√™n li·ªáu t∆∞∆°ng t·ª±
    similar_ingredients = {
        "th·ªãt heo": ["th·ªãt l·ª£n", "th·ªãt ba ch·ªâ", "ba ch·ªâ", "th·ªãt n·∫°c", "th·ªãt vai", "th·ªãt ƒë√πi"],
        "th·ªãt b√≤": ["b√≤", "thƒÉn b√≤", "g·∫ßu b√≤", "n·∫°m b√≤"],
        "th·ªãt g√†": ["g√†", "ƒë√πi g√†", "c√°nh g√†", "·ª©c g√†"],
        "th·ªãt v·ªãt": ["v·ªãt"],
        "h√†nh": ["h√†nh t√≠m", "h√†nh kh√¥", "c·ªß h√†nh", "h√†nh l√°", "h√†nh hoa"],
        "t·ªèi": ["c·ªß t·ªèi", "t·ªèi t∆∞∆°i", "t·ªèi kh√¥"],
        "·ªõt": ["·ªõt hi·ªÉm", "·ªõt s·ª´ng"],
        "n∆∞·ªõc m·∫Øm": ["m·∫Øm"],
        "mu·ªëi": ["mu·ªëi ƒÉn", "mu·ªëi tinh", "mu·ªëi h·∫°t"]
    }
    
    for ingredient in ingredients:
        normalized = ingredient.lower().strip()
        
        # Ki·ªÉm tra xem nguy√™n li·ªáu n√†y ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a
        if normalized in seen:
            continue
            
        # Ki·ªÉm tra xem c√≥ ph·∫£i l√† nguy√™n li·ªáu t∆∞∆°ng t·ª± kh√¥ng
        standardized_name = normalized
        for main_name, variants in similar_ingredients.items():
            if normalized in variants or any(variant in normalized for variant in variants):
                standardized_name = main_name
                break
                
        # Th√™m v√†o danh s√°ch k·∫øt qu·∫£
        normalized_ingredients.append(standardized_name)
        seen.add(normalized)
        
        # ƒê√°nh d·∫•u t·∫•t c·∫£ c√°c bi·∫øn th·ªÉ ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        for main_name, variants in similar_ingredients.items():
            if standardized_name == main_name:
                for variant in variants:
                    seen.add(variant)
    
    # Lo·∫°i b·ªè c√°c t·ª´ kh√¥ng ph·∫£i nguy√™n li·ªáu
    non_ingredients = ["c√°ch l√†m", "h∆∞·ªõng d·∫´n", "ch·∫ø bi·∫øn", "n·∫•u", "m√≥n", "ƒÉn", "ch√∫c", "ngon mi·ªáng"]
    filtered_ingredients = [ing for ing in normalized_ingredients if not any(word in ing.lower() for word in non_ingredients)]
    
    # S·∫Øp x·∫øp theo b·∫£ng ch·ªØ c√°i
    filtered_ingredients.sort()
    
    return filtered_ingredients

def check_ingredient_availability(ingredients):
    """Ki·ªÉm tra xem nguy√™n li·ªáu c√≥ s·∫µn trong c·ª≠a h√†ng kh√¥ng"""
    # L·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m t·ª´ database
    products = get_product_data()
    
    # N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu t·ª´ database, th·ª≠ ƒë·ªçc t·ª´ file JSON
    if not products:
        try:
            with open("products.json", "r", encoding="utf-8") as f:
                products = json.load(f)
        except:
            # N·∫øu kh√¥ng t√¨m th·∫•y file, th·ª≠ ƒë∆∞·ªùng d·∫´n kh√°c
            try:
                with open("data/products.json", "r", encoding="utf-8") as f:
                    products = json.load(f)
            except:
                # N·∫øu kh√¥ng c√≥ file n√†o, tr·∫£ v·ªÅ t·∫•t c·∫£ l√† kh√¥ng c√≥ s·∫µn
                return {ingredient: {"available": False} for ingredient in ingredients}
    
    # Ph√¢n lo·∫°i s·∫£n ph·∫©m theo danh m·ª•c
    categorized_products = {}
    for product in products:
        category = product.get("category", "").lower()
        if category not in categorized_products:
            categorized_products[category] = []
        categorized_products[category].append({
            "name": product["name"].lower(),
            "description": product.get("description", "").lower(),
            "category": category,
            "id": product.get("id", ""),
            "price": product.get("price", 0),
            "unit": product.get("unit", ""),
            "stock": product.get("stock", 0),
            "original": product
        })
    
    # Danh m·ª•c th·ª±c ph·∫©m v√† phi th·ª±c ph·∫©m
    food_categories = ["th·ª±c ph·∫©m", "rau c·ªß", "tr√°i c√¢y", "th·ªãt", "c√°", "h·∫£i s·∫£n", "gia v·ªã", "ƒë·ªì kh√¥", 
                      "ƒë·ªì u·ªëng", "b√°nh k·∫πo", "s·ªØa", "tr·ª©ng", "th·ª±c ph·∫©m ƒë√¥ng l·∫°nh", "th·ª±c ph·∫©m ch·∫ø bi·∫øn s·∫µn"]
    
    non_food_categories = ["ƒë·ªì d√πng", "m·ªπ ph·∫©m", "chƒÉm s√≥c c√° nh√¢n", "v·ªá sinh", "gi·∫∑t gi≈©", "t·∫©y r·ª≠a", 
                          "ƒë·ªì d√πng nh√† b·∫øp", "ƒë·ªì d√πng gia ƒë√¨nh", "vƒÉn ph√≤ng ph·∫©m", "ƒëi·ªán t·ª≠", "ƒëi·ªán gia d·ª•ng"]
    
    # T·ª´ kh√≥a lo·∫°i tr·ª´ cho t·ª´ng lo·∫°i nguy√™n li·ªáu
    exclusion_keywords = {
        "th·ªãt": ["gi·∫£", "chay", "kem", "b√°nh", "k·∫πo", "m√¨ g√≥i"],
        "c√°": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "rau": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "tr√°i c√¢y": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "gia v·ªã": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "d·∫ßu ƒÉn": ["g·ªôi", "x·∫£", "d∆∞·ª°ng", "kem", "s·ªØa t·∫Øm", "d∆∞·ª°ng th·ªÉ", "ƒë√°nh rƒÉng"],
        "n∆∞·ªõc m·∫Øm": ["ng·ªçt", "pepsi", "coca", "gi·∫∑t", "t·∫©y", "r·ª≠a"],
        "tr·ª©ng": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "h√†nh": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "t·ªèi": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"]
    }
    
    # Ki·ªÉm tra t·ª´ng nguy√™n li·ªáu
    result = {}
    
    for ingredient in ingredients:
        # Chu·∫©n h√≥a t√™n nguy√™n li·ªáu
        normalized = ingredient.lower().strip()
        
        # X√°c ƒë·ªãnh c√°c danh m·ª•c li√™n quan ƒë·∫øn th·ª±c ph·∫©m d·ª±a tr√™n nguy√™n li·ªáu
        relevant_food_categories = []
        
        # X√°c ƒë·ªãnh danh m·ª•c th·ª±c ph·∫©m d·ª±a tr√™n nguy√™n li·ªáu
        if any(word in normalized for word in ["th·ªãt", "s∆∞·ªùn", "ba ch·ªâ", "n·∫°c", "ƒë√πi", "c√°nh"]):
            relevant_food_categories.extend(["th·ªãt", "th·ª±c ph·∫©m t∆∞∆°i s·ªëng", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["c√°", "t√¥m", "m·ª±c", "cua", "gh·∫π", "s√≤", "h√†u"]):
            relevant_food_categories.extend(["h·∫£i s·∫£n", "c√°", "th·ª±c ph·∫©m t∆∞∆°i s·ªëng", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["rau", "c·ªß", "c·∫£i", "x√† l√°ch", "b·∫Øp c·∫£i"]):
            relevant_food_categories.extend(["rau c·ªß", "rau c·ªß qu·∫£", "th·ª±c ph·∫©m t∆∞∆°i s·ªëng", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["tr√°i", "qu·∫£", "t√°o", "cam", "chu·ªëi", "xo√†i"]):
            relevant_food_categories.extend(["tr√°i c√¢y", "rau c·ªß qu·∫£", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["n∆∞·ªõc m·∫Øm", "n∆∞·ªõc t∆∞∆°ng", "t∆∞∆°ng", "gia v·ªã", "mu·ªëi", "ti√™u", "ƒë∆∞·ªùng", "h·∫°t n√™m"]):
            relevant_food_categories.extend(["gia v·ªã", "ƒë·ªì kh√¥", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["d·∫ßu ƒÉn", "d·∫ßu h√†o", "d·∫ßu m√®", "b∆°"]):
            relevant_food_categories.extend(["d·∫ßu ƒÉn", "gia v·ªã", "ƒë·ªì kh√¥", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["g·∫°o", "b·ªôt", "ng≈© c·ªëc"]):
            relevant_food_categories.extend(["ƒë·ªì kh√¥", "g·∫°o", "b·ªôt", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["m√¨", "b√∫n", "ph·ªü", "mi·∫øn"]):
            relevant_food_categories.extend(["m√¨", "b√∫n", "ph·ªü", "ƒë·ªì kh√¥", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["s·ªØa", "ph√¥ mai", "b∆° s·ªØa"]):
            relevant_food_categories.extend(["s·ªØa", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["tr·ª©ng"]):
            relevant_food_categories.extend(["tr·ª©ng", "th·ª±c ph·∫©m t∆∞∆°i s·ªëng", "th·ª±c ph·∫©m"])
        elif any(word in normalized for word in ["h√†nh", "t·ªèi", "g·ª´ng", "·ªõt"]):
            relevant_food_categories.extend(["rau c·ªß", "gia v·ªã", "th·ª±c ph·∫©m t∆∞∆°i s·ªëng", "th·ª±c ph·∫©m"])
        elif "v·ªãt" in normalized:
            relevant_food_categories.extend(["th·ªãt", "th·ªãt v·ªãt", "th·ª±c ph·∫©m t∆∞∆°i s·ªëng", "th·ª±c ph·∫©m"])
        else:
            # M·∫∑c ƒë·ªãnh xem l√† th·ª±c ph·∫©m
            relevant_food_categories.extend(["th·ª±c ph·∫©m"])
        
        # L·∫•y t·ª´ kh√≥a lo·∫°i tr·ª´ cho nguy√™n li·ªáu n√†y
        current_exclusions = []
        for key, exclusions in exclusion_keywords.items():
            if key in normalized or normalized in key:
                current_exclusions.extend(exclusions)
        
        # T√¨m s·∫£n ph·∫©m ph√π h·ª£p
        matches = []
        
        # ∆Øu ti√™n t√¨m trong c√°c danh m·ª•c th·ª±c ph·∫©m li√™n quan
        for category_name, products_list in categorized_products.items():
            # Ki·ªÉm tra xem danh m·ª•c c√≥ ph·∫£i l√† th·ª±c ph·∫©m li√™n quan kh√¥ng
            is_relevant_category = any(food_cat in category_name for food_cat in relevant_food_categories)
            
            # N·∫øu l√† danh m·ª•c th·ª±c ph·∫©m li√™n quan, t√¨m ki·∫øm trong ƒë√≥
            if is_relevant_category:
                for product in products_list:
                    # B·ªè qua s·∫£n ph·∫©m ch·ª©a t·ª´ kh√≥a lo·∫°i tr·ª´
                    if any(excl in product["name"] or excl in product["description"] for excl in current_exclusions):
                        continue
                        
                    # Ki·ªÉm tra t√™n s·∫£n ph·∫©m c√≥ ch·ª©a nguy√™n li·ªáu kh√¥ng
                    if normalized in product["name"] or any(word in product["name"] for word in normalized.split() if len(word) > 2):
                        # Th√™m ƒëi·ªÉm ph√π h·ª£p ƒë·ªÉ s·∫Øp x·∫øp sau n√†y
                        product["match_score"] = 10
                        matches.append(product)
                    # Ki·ªÉm tra m√¥ t·∫£ s·∫£n ph·∫©m
                    elif normalized in product["description"]:
                        product["match_score"] = 5
                        matches.append(product)
        
        # N·∫øu kh√¥ng t√¨m th·∫•y trong danh m·ª•c th·ª±c ph·∫©m li√™n quan, t√¨m trong t·∫•t c·∫£ danh m·ª•c th·ª±c ph·∫©m
        if not matches:
            for category_name, products_list in categorized_products.items():
                # Ki·ªÉm tra xem danh m·ª•c c√≥ ph·∫£i l√† th·ª±c ph·∫©m kh√¥ng
                is_food_category = any(food_cat in category_name for food_cat in food_categories)
                
                # N·∫øu l√† danh m·ª•c th·ª±c ph·∫©m, t√¨m ki·∫øm trong ƒë√≥
                if is_food_category:
                    for product in products_list:
                        # B·ªè qua s·∫£n ph·∫©m ch·ª©a t·ª´ kh√≥a lo·∫°i tr·ª´
                        if any(excl in product["name"] or excl in product["description"] for excl in current_exclusions):
                            continue
                            
                        # Ki·ªÉm tra t√™n s·∫£n ph·∫©m c√≥ ch·ª©a nguy√™n li·ªáu kh√¥ng
                        if normalized in product["name"] or any(word in product["name"] for word in normalized.split() if len(word) > 2):
                            product["match_score"] = 8
                            matches.append(product)
                        # Ki·ªÉm tra m√¥ t·∫£ s·∫£n ph·∫©m
                        elif normalized in product["description"]:
                            product["match_score"] = 3
                            matches.append(product)
        
        # S·∫Øp x·∫øp k·∫øt qu·∫£ theo ƒë·ªô ph√π h·ª£p
        matches.sort(key=lambda x: (
            x.get("match_score", 0),  # ƒêi·ªÉm ph√π h·ª£p
            1 if normalized in x["name"] else 0,  # ∆Øu ti√™n t√™n s·∫£n ph·∫©m ch·ª©a ƒë√∫ng nguy√™n li·ªáu
            1 if any(cat in x["category"] for cat in relevant_food_categories) else 0  # ∆Øu ti√™n danh m·ª•c ph√π h·ª£p
        ), reverse=True)
        
        # L·ªçc k·∫øt qu·∫£ kh√¥ng li√™n quan d·ª±a tr√™n ƒëi·ªÉm ph√π h·ª£p
        filtered_matches = [m for m in matches if m.get("match_score", 0) >= 3]
        
        if filtered_matches:
            # L·∫•y s·∫£n ph·∫©m ph√π h·ª£p nh·∫•t
            best_match = filtered_matches[0]
            result[ingredient] = {
                "available": True,
                "product_name": best_match["original"]["name"],
                "price": best_match["price"],
                "unit": best_match["unit"],
                "stock": best_match.get("stock", "C√≥ s·∫µn")
            }
        else:
            result[ingredient] = {
                "available": False
            }
    
    return result

def format_price(price):
    """Format price with commas and VND"""
    return f"{price:,} VND"

def suggest_alternative_products(ingredient):
    """G·ª£i √Ω c√°c s·∫£n ph·∫©m thay th·∫ø khi kh√¥ng t√¨m th·∫•y nguy√™n li·ªáu"""
    from db_connector import get_product_data
    
    # L·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m t·ª´ database
    products = get_product_data()
    
    # N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu t·ª´ database, th·ª≠ ƒë·ªçc t·ª´ file JSON
    if not products:
        try:
            with open("products.json", "r", encoding="utf-8") as f:
                products = json.load(f)
        except:
            try:
                with open("data/products.json", "r", encoding="utf-8") as f:
                    products = json.load(f)
            except:
                return []
    
    # Chu·∫©n h√≥a t√™n nguy√™n li·ªáu
    normalized = ingredient.lower().strip()
    
    # Danh m·ª•c th·ª±c ph·∫©m v√† phi th·ª±c ph·∫©m
    food_categories = ["th·ª±c ph·∫©m", "rau c·ªß", "tr√°i c√¢y", "th·ªãt", "c√°", "h·∫£i s·∫£n", "gia v·ªã", "ƒë·ªì kh√¥", 
                      "ƒë·ªì u·ªëng", "b√°nh k·∫πo", "s·ªØa", "tr·ª©ng", "th·ª±c ph·∫©m ƒë√¥ng l·∫°nh", "th·ª±c ph·∫©m ch·∫ø bi·∫øn s·∫µn"]
    
    # T·ª´ kh√≥a lo·∫°i tr·ª´ cho t·ª´ng lo·∫°i nguy√™n li·ªáu
    exclusion_keywords = {
        "th·ªãt": ["gi·∫£", "chay", "kem", "b√°nh", "k·∫πo", "m√¨ g√≥i"],
        "c√°": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "rau": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "tr√°i c√¢y": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "gia v·ªã": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "d·∫ßu ƒÉn": ["g·ªôi", "x·∫£", "d∆∞·ª°ng", "kem", "s·ªØa t·∫Øm", "d∆∞·ª°ng th·ªÉ", "ƒë√°nh rƒÉng"],
        "n∆∞·ªõc m·∫Øm": ["ng·ªçt", "pepsi", "coca", "gi·∫∑t", "t·∫©y", "r·ª≠a"],
        "tr·ª©ng": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "h√†nh": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"],
        "t·ªèi": ["kem", "b√°nh", "k·∫πo", "n∆∞·ªõc gi·∫∑t", "t·∫©y r·ª≠a"]
    }
    
    # X√°c ƒë·ªãnh lo·∫°i nguy√™n li·ªáu ƒë·ªÉ t√¨m thay th·∫ø ph√π h·ª£p
    ingredient_type = ""
    if any(word in normalized for word in ["th·ªãt", "s∆∞·ªùn", "ba ch·ªâ", "n·∫°c", "ƒë√πi", "c√°nh"]):
        ingredient_type = "th·ªãt"
    elif any(word in normalized for word in ["c√°", "t√¥m", "m·ª±c", "cua", "gh·∫π", "s√≤", "h√†u"]):
        ingredient_type = "h·∫£i s·∫£n"
    elif any(word in normalized for word in ["rau", "c·ªß", "c·∫£i", "x√† l√°ch", "b·∫Øp c·∫£i"]):
        ingredient_type = "rau c·ªß"
    elif any(word in normalized for word in ["tr√°i", "qu·∫£", "t√°o", "cam", "chu·ªëi", "xo√†i"]):
        ingredient_type = "tr√°i c√¢y"
    elif any(word in normalized for word in ["n∆∞·ªõc m·∫Øm", "n∆∞·ªõc t∆∞∆°ng", "t∆∞∆°ng", "gia v·ªã", "mu·ªëi", "ti√™u", "ƒë∆∞·ªùng", "h·∫°t n√™m"]):
        ingredient_type = "gia v·ªã"
    elif any(word in normalized for word in ["d·∫ßu ƒÉn", "d·∫ßu h√†o", "d·∫ßu m√®", "b∆°"]):
        ingredient_type = "d·∫ßu ƒÉn"
    elif any(word in normalized for word in ["g·∫°o", "b·ªôt", "ng≈© c·ªëc"]):
        ingredient_type = "ƒë·ªì kh√¥"
    elif any(word in normalized for word in ["m√¨", "b√∫n", "ph·ªü", "mi·∫øn"]):
        ingredient_type = "m√¨ b√∫n ph·ªü"
    elif any(word in normalized for word in ["s·ªØa", "ph√¥ mai", "b∆° s·ªØa"]):
        ingredient_type = "s·ªØa"
    elif any(word in normalized for word in ["tr·ª©ng"]):
        ingredient_type = "tr·ª©ng"
    elif any(word in normalized for word in ["h√†nh", "t·ªèi", "g·ª´ng", "·ªõt"]):
        ingredient_type = "gia v·ªã"
    elif "v·ªãt" in normalized:
        ingredient_type = "th·ªãt"
    else:
        ingredient_type = "th·ª±c ph·∫©m"
    
    # L·∫•y t·ª´ kh√≥a lo·∫°i tr·ª´ cho nguy√™n li·ªáu n√†y
    current_exclusions = []
    for key, exclusions in exclusion_keywords.items():
        if key in normalized or normalized in key:
            current_exclusions.extend(exclusions)
    
    # Ph√¢n lo·∫°i s·∫£n ph·∫©m theo danh m·ª•c
    categorized_products = {}
    for product in products:
        category = product.get("category", "").lower()
        if category not in categorized_products:
            categorized_products[category] = []
        categorized_products[category].append({
            "name": product["name"].lower(),
            "description": product.get("description", "").lower(),
            "category": category,
            "id": product.get("id", ""),
            "price": product.get("price", 0),
            "unit": product.get("unit", ""),
            "stock": product.get("stock", 0),
            "original": product
        })
    
    # T√¨m c√°c s·∫£n ph·∫©m thay th·∫ø
    alternatives = []
    
    # √Ånh x·∫° c√°c lo·∫°i thay th·∫ø theo lo·∫°i nguy√™n li·ªáu
    alternative_mapping = {
        "th·ªãt": ["th·ªãt", "h·∫£i s·∫£n", "ƒë·∫°m th·ª±c v·∫≠t", "ƒë·ªì chay"],
        "h·∫£i s·∫£n": ["h·∫£i s·∫£n", "th·ªãt", "ƒë·∫°m th·ª±c v·∫≠t", "ƒë·ªì chay"],
        "rau c·ªß": ["rau c·ªß", "rau c·ªß qu·∫£", "th·ª±c ph·∫©m t∆∞∆°i s·ªëng"],
        "tr√°i c√¢y": ["tr√°i c√¢y", "rau c·ªß qu·∫£"],
        "gia v·ªã": ["gia v·ªã", "ƒë·ªì kh√¥"],
        "d·∫ßu ƒÉn": ["d·∫ßu ƒÉn", "gia v·ªã", "d·∫ßu"],
        "ƒë·ªì kh√¥": ["ƒë·ªì kh√¥", "th·ª±c ph·∫©m"],
        "m√¨ b√∫n ph·ªü": ["m√¨", "b√∫n", "ph·ªü", "ƒë·ªì kh√¥"],
        "s·ªØa": ["s·ªØa", "ƒë·ªì u·ªëng"],
        "tr·ª©ng": ["tr·ª©ng", "ƒë·∫°m", "th·ªãt"],
        "th·ª±c ph·∫©m": ["th·ª±c ph·∫©m"]
    }
    
    # L·∫•y c√°c lo·∫°i thay th·∫ø cho nguy√™n li·ªáu hi·ªán t·∫°i
    alternative_types = alternative_mapping.get(ingredient_type, ["th·ª±c ph·∫©m"])
    
    # T√¨m s·∫£n ph·∫©m thay th·∫ø t·ª´ c√°c danh m·ª•c li√™n quan
    for alt_type in alternative_types:
        for category_name, products_list in categorized_products.items():
            # Ki·ªÉm tra xem danh m·ª•c c√≥ ph√π h·ª£p v·ªõi lo·∫°i thay th·∫ø kh√¥ng
            if alt_type in category_name:
                for product in products_list:
                    # B·ªè qua s·∫£n ph·∫©m ch·ª©a t·ª´ kh√≥a lo·∫°i tr·ª´
                    if any(excl in product["name"] or excl in product["description"] for excl in current_exclusions):
                        continue
                        
                    # Ki·ªÉm tra xem s·∫£n ph·∫©m n√†y kh√¥ng ph·∫£i l√† nguy√™n li·ªáu g·ªëc
                    if normalized not in product["name"] and not any(word in product["name"] for word in normalized.split() if len(word) > 2):
                        # Ch·ªâ l·∫•y s·∫£n ph·∫©m th·ª±c ph·∫©m
                        if any(food_cat in category_name for food_cat in food_categories):
                            # T√≠nh ƒëi·ªÉm ph√π h·ª£p
                            relevance_score = 2 if alt_type == ingredient_type else 1
                            
                            alternatives.append({
                                "name": product["original"]["name"],
                                "price": product.get("price", 0),
                                "unit": product.get("unit", ""),
                                "category": category_name,
                                "relevance": relevance_score
                            })
                            
                            # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng s·∫£n ph·∫©m thay th·∫ø m·ªói danh m·ª•c
                            if len(alternatives) >= 10:
                                break
    
    # S·∫Øp x·∫øp theo ƒë·ªô li√™n quan v√† gi√° c·∫£
    alternatives.sort(key=lambda x: (x.get("relevance", 0), -x.get("price", 0)), reverse=True)
    
    # Lo·∫°i b·ªè c√°c s·∫£n ph·∫©m tr√πng l·∫∑p
    unique_alternatives = []
    seen_names = set()
    for alt in alternatives:
        if alt["name"].lower() not in seen_names:
            seen_names.add(alt["name"].lower())
            unique_alternatives.append(alt)
    
    # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng g·ª£i √Ω
    return unique_alternatives[:3]

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=5000, debug=True) 