import os
import json
from typing import List, Dict, Any
import pandas as pd
from dotenv import load_dotenv
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from db_connector import get_product_data, get_order_data, get_faq_data

# Load environment variables
load_dotenv()

class RagChatbot:
    def __init__(self):
        # Initialize embeddings model (using a free model from Hugging Face)
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # Create or load vector database
        self.create_or_load_vector_db()
        
        # Initialize language model (if you have an OpenAI API key)
        # Otherwise, you can use a local model or other free alternatives
        api_key = os.getenv("OPENAI_API_KEY", "")
        if api_key:
            self.llm = ChatOpenAI(temperature=0, api_key=api_key)
        else:
            # Fall back to a simple response generator if no API key
            self.llm = None
            
        # Load FAQ data for direct matching
        self.faq_data = self.load_faq_data()
            
        # Create QA chain
        if self.llm:
            template = """
            Báº¡n lÃ  trá»£ lÃ½ áº£o cá»§a website siÃªu thá»‹ thá»±c pháº©m sáº¡ch. HÃ£y tráº£ lá»i cÃ¢u há»i cá»§a khÃ¡ch hÃ ng má»™t cÃ¡ch chuyÃªn nghiá»‡p, 
            thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch. Dá»±a vÃ o thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p bÃªn dÆ°á»›i Ä‘á»ƒ tráº£ lá»i.
            Náº¿u khÃ´ng cÃ³ thÃ´ng tin, hÃ£y nÃ³i ráº±ng báº¡n khÃ´ng cÃ³ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i vÃ  Ä‘á» nghá»‹ khÃ¡ch hÃ ng 
            liÃªn há»‡ vá»›i bá»™ pháº­n chÄƒm sÃ³c khÃ¡ch hÃ ng.
            
            ThÃ´ng tin: {context}
            
            CÃ¢u há»i: {question}
            
            Tráº£ lá»i:
            """
            
            prompt = PromptTemplate(
                template=template,
                input_variables=["context", "question"]
            )
            
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.vector_db.as_retriever(search_kwargs={"k": 3}),
                chain_type_kwargs={"prompt": prompt}
            )
    
    def load_faq_data(self):
        """Load FAQ data for direct matching"""
        try:
            with open("data/faq.json", "r", encoding="utf-8") as f:
                faq_data = json.load(f)
            return faq_data
        except Exception as e:
            print(f"Error loading FAQ data: {str(e)}")
            return []
    
    def create_or_load_vector_db(self):
        """Create or load the vector database with all documents"""
        # Check if vector database exists
        if os.path.exists("vector_db"):
            # Load existing vector database
            self.vector_db = FAISS.load_local("vector_db", self.embeddings)
            print("Loaded existing vector database")
        else:
            # Create new vector database from documents
            documents = self.prepare_documents()
            
            # Create text splitter
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            
            # Split documents
            splits = text_splitter.split_documents(documents)
            
            # Create vector database
            self.vector_db = FAISS.from_documents(splits, self.embeddings)
            
            # Save vector database
            self.vector_db.save_local("vector_db")
            print("Created and saved new vector database")
    
    def prepare_documents(self) -> List[Document]:
        """Prepare documents from various sources"""
        documents = []
        
        # Add FAQ documents
        faq_docs = self.prepare_faq_documents()
        documents.extend(faq_docs)
        
        # Add product documents
        product_docs = self.prepare_product_documents()
        documents.extend(product_docs)
        
        # Add policy documents
        policy_docs = self.prepare_policy_documents()
        documents.extend(policy_docs)
        
        # Add database documents
        db_docs = self.prepare_db_documents()
        documents.extend(db_docs)
        
        return documents
    
    def prepare_faq_documents(self) -> List[Document]:
        """Prepare FAQ documents"""
        # Load FAQ data from json file
        with open("data/faq.json", "r", encoding="utf-8") as f:
            faq_data = json.load(f)
        
        # Also try to get FAQ data from database
        try:
            db_faq_data = get_faq_data()
            if db_faq_data:
                faq_data.extend(db_faq_data)
        except:
            pass
        
        # Create documents
        documents = []
        for item in faq_data:
            content = f"CÃ¢u há»i: {item['question']}\nTráº£ lá»i: {item['answer']}"
            doc = Document(
                page_content=content,
                metadata={"source": "FAQ", "category": item.get("category", "Chung")}
            )
            documents.append(doc)
        
        return documents
    
    def prepare_product_documents(self) -> List[Document]:
        """Prepare product documents"""
        # Load product data from json file
        with open("data/products.json", "r", encoding="utf-8") as f:
            product_data = json.load(f)
        
        # Also try to get product data from database
        try:
            db_product_data = get_product_data()
            if db_product_data:
                product_data.extend(db_product_data)
        except:
            pass
        
        # Create documents
        documents = []
        for product in product_data:
            content = f"""
            TÃªn sáº£n pháº©m: {product['name']}
            MÃ´ táº£: {product['description']}
            GiÃ¡: {product['price']} Ä‘á»“ng
            Danh má»¥c: {product['category']}
            Nguá»“n gá»‘c: {product.get('origin', 'Viá»‡t Nam')}
            Chá»©ng nháº­n: {', '.join(product.get('certifications', []))}
            """
            doc = Document(
                page_content=content,
                metadata={"source": "Product", "category": product["category"]}
            )
            documents.append(doc)
        
        return documents
    
    def prepare_policy_documents(self) -> List[Document]:
        """Prepare policy documents"""
        # Load policy data
        policy_files = [
            "data/shipping_policy.txt",
            "data/return_policy.txt",
            "data/payment_policy.txt",
            "data/privacy_policy.txt"
        ]
        
        documents = []
        for file_path in policy_files:
            if os.path.exists(file_path):
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                
                policy_type = os.path.basename(file_path).replace("_policy.txt", "").replace("_", " ").title()
                
                doc = Document(
                    page_content=content,
                    metadata={"source": "Policy", "type": policy_type}
                )
                documents.append(doc)
        
        return documents
    
    def prepare_db_documents(self) -> List[Document]:
        """Prepare documents from database"""
        documents = []
        
        # Try to get order data from database
        try:
            order_data = get_order_data()
            if order_data:
                for order in order_data:
                    content = f"""
                    MÃ£ Ä‘Æ¡n hÃ ng: {order['order_id']}
                    Tráº¡ng thÃ¡i: {order['status']}
                    Tá»•ng tiá»n: {order['total']} Ä‘á»“ng
                    PhÆ°Æ¡ng thá»©c thanh toÃ¡n: {order['payment_method']}
                    PhÆ°Æ¡ng thá»©c váº­n chuyá»ƒn: {order['shipping_method']}
                    """
                    doc = Document(
                        page_content=content,
                        metadata={"source": "Order", "order_id": order['order_id']}
                    )
                    documents.append(doc)
        except:
            pass
        
        return documents
    
    def find_direct_faq_match(self, question: str) -> str:
        """Find a direct match in FAQ data"""
        # Normalize the question for comparison
        normalized_question = question.lower().strip()
        
        # Check for exact match
        for item in self.faq_data:
            if item['question'].lower().strip() == normalized_question:
                return item['answer']
        
        # Check for substring match
        for item in self.faq_data:
            if normalized_question in item['question'].lower() or item['question'].lower() in normalized_question:
                # Calculate similarity score (basic)
                similarity = len(set(normalized_question.split()) & set(item['question'].lower().split())) / len(set(normalized_question.split() + item['question'].lower().split()))
                if similarity > 0.6:  # Threshold for similarity
                    return item['answer']
        
        return ""
    
    def get_cooking_recipe(self, dish_name: str) -> str:
        """Get cooking recipe information using ChatGPT"""
        if not self.llm:
            return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ truy cáº­p Ä‘Æ°á»£c thÃ´ng tin cÃ´ng thá»©c náº¥u Äƒn lÃºc nÃ y."
            
        prompt = f"""
        Báº¡n lÃ  má»™t chuyÃªn gia áº©m thá»±c Viá»‡t Nam. HÃ£y cung cáº¥p thÃ´ng tin chi tiáº¿t vá» nguyÃªn liá»‡u cáº§n thiáº¿t Ä‘á»ƒ náº¥u mÃ³n {dish_name}.
        
        YÃªu cáº§u:
        1. Liá»‡t kÃª Ä‘áº§y Ä‘á»§ cÃ¡c nguyÃªn liá»‡u cáº§n thiáº¿t
        2. PhÃ¢n loáº¡i nguyÃªn liá»‡u thÃ nh cÃ¡c nhÃ³m: nguyÃªn liá»‡u chÃ­nh, gia vá»‹, vÃ  nguyÃªn liá»‡u phá»¥ (náº¿u cÃ³)
        3. Ghi rÃµ sá»‘ lÆ°á»£ng cho má»—i nguyÃªn liá»‡u
        4. ThÃªm má»™t vÃ i lÆ°u Ã½ quan trá»ng khi chá»n nguyÃªn liá»‡u
        5. Äá»‹nh dáº¡ng cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… Ä‘á»c vá»›i cÃ¡c emoji phÃ¹ há»£p
        
        HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t vÃ  sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng markdown Ä‘á»ƒ trÃ¬nh bÃ y Ä‘áº¹p máº¯t.
        """
        
        try:
            response = self.llm.predict(prompt)
            # ThÃªm thÃ´ng tin vá» nguá»“n dá»¯ liá»‡u
            response += "\n\nğŸ’¡ ThÃ´ng tin Ä‘Æ°á»£c cung cáº¥p bá»Ÿi chuyÃªn gia áº©m thá»±c AI"
            # ThÃªm gá»£i Ã½ tÃ¬m kiáº¿m nguyÃªn liá»‡u
            response += "\n\nğŸ” Báº¡n cÃ³ thá»ƒ gÃµ \"TÃ¬m cÃ¡c nguyÃªn liá»‡u nhÆ° trÃªn\" Ä‘á»ƒ kiá»ƒm tra xem cá»­a hÃ ng cÃ³ sáºµn nhá»¯ng nguyÃªn liá»‡u nÃ y khÃ´ng."
            return response
        except Exception as e:
            print(f"Error getting cooking recipe: {str(e)}")
            return "Xin lá»—i, cÃ³ lá»—i xáº£y ra khi tÃ¬m thÃ´ng tin cÃ´ng thá»©c náº¥u Äƒn. Vui lÃ²ng thá»­ láº¡i sau."

    def get_answer(self, question: str) -> str:
        # Æ¯u tiÃªn nháº­n diá»‡n cÃ¢u há»i vá» mÃ³n Äƒn trÆ°á»›c
        cooking_keywords = ["náº¥u", "cÃ´ng thá»©c", "nguyÃªn liá»‡u", "cÃ¡ch lÃ m"]
        if any(keyword in question.lower() for keyword in cooking_keywords):
            # Extract dish name from question
            dish_name = question.lower()
            for keyword in cooking_keywords:
                dish_name = dish_name.replace(keyword, "").strip()
            return self.get_cooking_recipe(dish_name)
        
        # Náº¿u khÃ´ng pháº£i cÃ¢u há»i vá» mÃ³n Äƒn, má»›i tÃ¬m trong FAQ/sáº£n pháº©m
        faq_answer = self.find_direct_faq_match(question)
        if faq_answer:
            return faq_answer

        # Náº¿u khÃ´ng cÃ³, dÃ¹ng QA chain
        if self.llm:
            try:
                result = self.qa_chain({"query": question})
                return result["result"]
            except Exception as e:
                print(f"Error in QA chain: {str(e)}")
                return self.generate_fallback_response(question)
        else:
            return self.generate_fallback_response(question)
    
    def generate_fallback_response(self, question: str) -> str:
        """Generate a simple response based on retrieved documents"""
        docs = self.vector_db.similarity_search(question, k=2)
        
        if not docs:
            return "Xin lá»—i, tÃ´i khÃ´ng cÃ³ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a báº¡n. Vui lÃ²ng liÃªn há»‡ vá»›i bá»™ pháº­n chÄƒm sÃ³c khÃ¡ch hÃ ng qua sá»‘ Ä‘iá»‡n thoáº¡i 1900 1234 Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£."
        
        response = "Dá»±a trÃªn thÃ´ng tin tÃ´i cÃ³:\n\n"
        for i, doc in enumerate(docs):
            response += f"{doc.page_content}\n\n"
        
        response += "Náº¿u báº¡n cáº§n thÃªm thÃ´ng tin, vui lÃ²ng liÃªn há»‡ vá»›i chÃºng tÃ´i qua sá»‘ Ä‘iá»‡n thoáº¡i 1900 1234."
        return response 